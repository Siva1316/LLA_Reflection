# Data Ingestion
version: v1
name: modem-data-trng-env
type: workflow
tags:
  - crm
  - tainingenv
description: Ingesting data in lakehouse
workflow:
  # schedule:
  #   cron: '*/2 * * * *'
  #   endOn: '2025-01-21T22:00:00Z'
  #   concurrencyPolicy: Forbid
  dag:
    - name: dg-modem-data
      # title: flatten Data Ingester
      description: The job ingests modem data from postgres into icebase zone
      spec:
        tags:
          - crm
        stack: flare:6.0
        compute: runnable-default
        stackSpec:
          driver:
            coreLimit: 2000m
            cores: 2
            memory: 3000m
          executor:
            coreLimit: 3000m
            cores: 2
            instances: 2
            memory: 4000m
          job:
            explain: true
            inputs:
              - name: modem_data
                dataset: dataos://modempg:public/modem_info
                format: csv
                options:
                  driver: org.postgresql.Driver
            logLevel: INFO
            outputs:
              - name: output
                dataset: dataos://lakehouse:siva/modem_data?acl=rw
                format: Iceberg
                options:
                  saveMode: overwrite
                  iceberg:
                    properties:
                      write.format.default: parquet
                      write.metadata.compression-codec: gzip
            steps:
              - sequence:
                  - name: output
                    sql: >
                      SELECT 
                        CAST(to_timestamp(timestamp, 'MM/DD/YYYY HH24:MI') AS TIMESTAMP) as timestamp,
                        modem_id 
                      FROM modem_data;
                    functions:
                      - name: cleanse_column_names
                      - name: change_column_case
                        case: lower




